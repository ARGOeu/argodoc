- Start Date: 2016-02-03
- RFC PR:

# Summary

This is an RFC for ARGO Compute Engine to support metric data received from two
or more monitoring engines enabled in active-active mode

# Motivation

Till now ARGO Compute Engine received metric data from a distributed monitoring
engine involving Nagios nodes dedicated for each high-level group.

With the introduction of a Centralized Single Monitoring Engine, accompanied with
an HA plan to run two of them in active-active setup, Compute Engine needs to
be able to accept metric data from two (or more) centralized sources at the same time
increasing the resolution of the metric Timelines.



# Detailed design

Right now, metric data generated by the Monitoring Engine, are gathered from ARGO Compute Engine and used
as events to populate timelines (regarding service endpoints). With the HA scenario of two central Monitoring engines
running in active-active mode the metric data will be doubled.

Each timeline will be populated with events originating from both of the Monitoring Instances. In the case that one of them
is considered problematic, the resulting timeline will include both legit and wrong events ~ thus corrupted. There should be
a mechanism to be able to request exclusions of metric data per monitoring engine for a designated period of time.

Thus there are two major design goals for the Compute Engine:

* Able to accept data from multiple monitoring engines ...thus multiple values in the monitoring_host avro field
* Able to exclude metric data for specific time periods for problematic monitoring engines (based again on monitoring_host field and timestamp)

The exclusion of problematic monitoring engines is implemented building upon the available recomputation request.
Extra information about excluding monitoring engines will be appended in the available recomputation schema.

Previous recomputation schema:

```
json
[{
  "reason": "testing_compute_engine",
  "start_time": "2013-12-08T12:03:44Z",
  "end_time": "2013-12-10T12:03:44Z",
  "exclude": [
    "SITE-A",
    "SITE-B"
  ],
  "status": "running",
  "timestamp": "2015-02-01 14:58:40"
}]
```

Refactored recomputation schema:

```
json
[{
  "reason": "testing_compute_engine",
  "start_time": "2013-12-08T12:03:44Z",
  "end_time": "2013-12-10T12:03:44Z",
  "exclude": [
    "SITE-A",
    "SITE-B"
  ],
  "status": "running",
  "timestamp": "2015-02-01 14:58:40",
  "exclude_monitoring_source": [
    { "host": "monA",
      "start_time": "2013-12-08T12:03:44Z",
      "end_time": "2013-12-08T15:03:44Z"
    }]
}]
```

# Implementation Details

Implementation includes changes in Apache Pig Scripts used in computations as well in the custom UDF Java Classes.

Specifically:
* Accept metric data for different monitoring_host values
* Parse extra monitoring field in recomputation.json inside RecomputationManager class
* Ask RecomputationManager if a monitoring engine is excluded for a specific timestamp
* Use Refactored RecompManager in PickEndpoints Filter UDF to filter metric data based on monitoring_host and timestamp
* Add unit tests for both recManager and PickEndpoints UDF
* Update accordingly compute-ar.pig, compute-status.pig UDF definitions and calls


# Unresolved questions

Need to specify the administrative process of issuing a recomputation request which includes
exclusion of a monitoring engine's metric data.
